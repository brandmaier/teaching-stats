---
title: "Einführung in die Bayessche Statistik"
subtitle: "<br/>Probelehrveranstaltung"
author: "Andreas Brandmaier"
institute: ""
#date: "`r Sys.Date()`"
date: "2021-02-11"
output:
  xaringan::moon_reader:
    css: [default,  "extra.css","sydney.css", "sydney-fonts.css"]
#    css: [robot]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r xaringanExtra, echo=FALSE, message=FALSE, warning=FALSE}
#xaringanExtra::use_xaringan_extra(c( "animate_css", "tachyons"))

library(here)
library(tidyverse)
library(ggx)
#source(here("R/scripts.R"))
source("R/scripts.R")
```

# Ziel der Inferenzstatistik

.hide[fill]
.hide[fill]

.larger[

.read_more[Um aus Daten einer begrenzten Anzahl Personen auf eine große Anzahl von Menschen schließen kann, befassen wir uns mit der Inferenzstatistik.] 

.read_more[Allgemeingültigkeit]

.read_more[Quantifizierung der Unsicherheit]

]

<!--.read_more[Typische Fragen in der Psychologie sind:]

 - Wirkt eine neue Therapieform B besser als eine Therapieform A?
- Gibt es einen Zusammenhang zwischen Computerspielen und Gewalt bei Jugendlichen?
- Werden attraktivere Menschen als erfolgreicher eingeschätzt? -->

---


# Ein Beispiel - Mittelwerte schätzen

.question[Fragestellung: ] Haben Studierende aus Potsdam im Mittel einen höheren IQ als 100?

.pull-left[

Die Stichprobe $y_1,\ldots, y_{10}$ sei:

```{r iq, eval=TRUE, echo=FALSE, fig.height=5,warning=FALSE,results="hide",message=FALSE}
set.seed(234)
iqdat <- tibble(x= rnorm(10,mean=110,sd=10))
ggplot(iqdat,aes(x=x))+geom_boxplot()+ geom_point(y=0,size=8)+xlab("IQ")+
  theme(text=element_text(size=25))+
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())+
  xlim(60,140)
```
]
.pull-right[

Dabei sei $\mu$ der unbekannte wahre Mittelwert der Potsdamer Studierenden

Unsere Modellannahme sei:

IQ-Test Ergebnisse sind normalverteilt mit wahrem Mittelwert $\mu$ und wahrer Varianz $\sigma^2$.
]

---

# Frequentistischer Ansatz:

.pull-left[
## Schätzen

Unter allen möglichen Normalverteilungen, wähle die, die am plausibelsten die Daten erzeugt hat:

```{r echo=FALSE, fig.height=4, fig.width=6}
source("R/likelihood.R")

```

]

--

.pull-right[
## Testen

Wie plausibel sind die Beobachtungen (oder extremer) unter einem Nullmodell?

```{r echo=FALSE, fig.height=4, fig.width=6, results="hide", warning=FALSE}
source("R/t-verteilung.R")
```
]

---

# Frequentistischer Ansatz

Grundsätzlich basiert Schätzen und Testen auf der Plausibilitätsfunktion (Likelihood):
<br>
.pull-left[
## Schätzen

.largermath[
$$\arg \max_\theta P\left( D | M_\theta \right)$$
]



]

.pull-right[
## Testen

.largermath[

$$P\left(D | M_0 \right) $$
]
]

<br><br><br><br>

.med[
.read_more[Wir halten fest, dass beide Ansätze auf .emph[bedingten Wahrscheinlichkeiten] basieren.]
]
---

# Missverständnisse in der frequentistischen Inferenz

- $p < 0.5$: Wir nehmen die Null-Hypothese anXXX

- 

---

class: segue-large-red

.bigfont[
Idee: Können wir $P\left(M | D \right)$ aus $P\left(D | M \right)$ berechnen?
]

---


# Der Satz von Bayes

Bayesianische Ansätze folgen der folgenden charakteristischen Struktur, die sich aus der bedingten Wahrscheinlichkeit ableiten lassen:

.largemath[
$$P \left( A | B \right) = \frac{ P\left(B | A \right) \times  P\left( A \right)   }{P\left(B \right)  } $$
]

---

# Vampirismus und der Satz von Bayes &#129415;


```{r echo=FALSE}
# adapted from Richard McElreath's fantastic book
PrPV <- .95
PrPM <- 0.01
PrV <- 0.001
PrP <- PrPV*PrV + PrPM*(1-PrV)

PrVP <- PrPV*PrV/PrP
```

Bekannt sei ein Test, der mit einer Erfolgschance von `r round(PrPV*100)`% Vampirismus detektiert. Wie hoch ist die Chance, bei positivem Ergebnis, ein Vampir zu sein?

$$P\left( Vampir | + \right) = \frac{ P\left( + | Vampir \right) \times  P\left(Vampir \right)   }{  P\left( + \right)  } $$

- $P \left( + | Vampir \right) =$ `r PrPV`
- $P \left( Vampir \right) =$ `r PrV`
- $P \left( + \right) =$  `r PrP`

Erlaubt uns den Schluss:

- $P \left( Vampir | + \right) =$ `r round(PrVP,2)`

---

# Bayesianischer Ansatz

.read_more[Idee:] Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen

.largermath[
$$ P\left( Modell | Daten \right) = \frac{ P\left(Daten | Modell\right) \cdot P\left( Modell \right) }{ P\left( Daten \right) } $$
]


.hide[Der Nenner P(Daten) ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

# Bayesianischer Ansatz

.hide[Idee: Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen
]

.largermath[
$$ \underbrace{P\left( Modell | Daten \right)}_{Posterior} = \frac{ \overbrace{P\left(Daten | Modell\right)}^{Likelihood} \cdot \overbrace{P\left( Modell \right)}^{Prior} }{ P\left( Daten \right)  } $$
]


.read_more[Der Nenner $P(Daten)$ ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

class:segue-large-red

.bigfont[
Aber Moment... was ist denn die _Wahrscheinlichkeit eines Modells_ oder _einer Hypothese_ überhaupt?
]

---


# Frequentistische Postulate

(nochmal zurück zum Start)

- Wahrscheinlichkeiten beziehen sich auf .emph[relative Häufigkeit] von Ereignisse bei einer großen Anzahl gleicher, wiederholter Durchführungen eines Zufallsexperiments. Wahrscheinlichkeiten sind objektive Eigenschaften der echten Welt.

- Die wahren -emph[Parameter sind unbekannte Konstanten]. Weil sie nicht veränderlich sind, kann man keine probabilistischen Aussagen über sie treffen.

- Ein Modell, bzw. die Hypothese die es repräsentiert, ist immer entweder wahr oder falsch.


---


# Wahrscheinlichkeitsbegriff

.pull-left[

.content-box-blue[Frequentistische Perspektive]

Wahrscheinlichkeit ist die .highlight[relative Häufigkeit] (Frequenz) eines Ereignis bei
sehr häufiger (unendlich oft) Wiederholung

]

.pull-right[

.content-box-gray[Bayesianische Perspektive]

Wahrscheinlichkeit ist der Ausdruck eines .highlight[Grad der Überzeugung] (_"degree of belief"_)

]

.pull-down[

Obwohl wir dieselbe Axiomatik der Wahrscheinlichkeitsrechnung nutzen, ist dies ein entscheidender philosophischer Unterschied. 

]

---

# Prior, Likelihood, und Posterior

.pull-left[
Beispiel: Statistisches Modell mit einem Parameter (z.B., Mittlerer IQ)

- .blue[Prior]: Glaubwürdigkeit aller möglichen Mittelwerte
- .red[Likelihood]: Plausibilität gegeben den Daten
- .green[Posterior]: Glaubwürdigkeit nach Beobachtung der Daten

.med[
.green[Posterior] $\propto$ .red[Likelihood] $\times$ .blue[Prior]:

]
]

.pull-right[

```{r fig.width=7, fig.height=7, echo=FALSE, message=FALSE}
source("R/schematic-bayes.R")
```
]

---

# Posterior

Das Ergebnis einer Schätzung ist der Posterior:

.pull-left[

- Enthält nicht nur einen einzelnen Punktschätzer (z.B. Effektstärke)

- Für jeden möglichen Parameterwert erhalten wir eine Wahrscheinlichkeit

- Spezifiziert vollständig unsere Unsicherheit

- Erlaubt (endlich!) Aussagen wie, das 95%-Intervall (.emph[credibility interval]) enthält zu 95% den wahren Parameter
]

.pull-right[

```{r echo=FALSE, warning=FALSE}
source("R/posterior.R")
```

]

---

# Wann spielt der Prior (k)eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]

.pull-right[
```{r fig.width=7, fig.height=7, echo=FALSE}
prior_sd <- 35
source("R/schematic-bayes.R")
```
]
---


class:segue-large-red

.bigfont[
Woher kommt der _Prior_ überhaupt?
]

--

# Beispiel: Beschränkung

```{r echo=FALSE, fig.width=12, fig.height=6}
source("R/prior_demo.R")
prior.demo(1)
```

---

# Beispiel: Informierter Prior

```{r echo=FALSE, fig.width=12, fig.height=6}
prior.demo(2)
```

---

# Woher kommt der Prior?

Es gibt verschiedene Wege, Priors zu wählen:

- Flache und uninformierte Priors
- Sinnvolle Beschränkungen des Parameterraums (z.B. Nicht-Negativität)
- Vorwissen
- Expertenmeinungen (elicited priors)


---

class: segue-large-gold

.bigfont[
Und was ist daran so kompliziert?
]
---

# Bayessche Integrale

Für viele Bayessche Anwendung benötigen wir Integrale, z.B., für

-   Berechnung der Evidenz in der Posterior-Verteilung:

$$P\left(\theta | D \right) = \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ P\left D \right) } =  \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ \int{ P\left( D | \theta  \right) P\left(\theta \right)} d\theta } $$
- Punkt- und Intervallschätzer, wie z.B. Mean oder Credibility Region

$$\hat{\mu} = \int \theta \cdot P\left(\theta | D \right)  d\theta $$
  

- Randverteilung einzelner Parameter
- Modellvergleich mit dem _emph[Bayes Faktor]

---

# Bayesianische Integrale lösen

Es existieren verschiedene Ansätze:

.read_more[] Analytische Lösungen mit .emph[konjugierten Priors]

  Bestimmte statistische Modelle haben Priors, die zu Posteriors führen, die aus derselben Verteilungsfamilie stammen
  
- Approximationen wie bspw. .emph[Variational Bayes]

  Finde einfache Verteilungen, die den wahren Posterior annähern
  
- .emph[Monte Carlo Markov Chains] (MCMC)

  Anstatt exakt zu rechnen, ziehen wir zufällig aus der Posteriorverteilung und rechnen mit den Samples weiter

---


# Zusammenfassung

Die Bayessche Statistik 

- benutzt Wahrscheinlichkeiten um Unsicherheiten zu beschreiben
- erfordert die Spezifikation von Prior-Verteilungen aller Modellparameter
- hat eher subjektiven Charakter (aber auch die Wahl der Likelihood ist subjektiv)
- Priors können aber auch uninformativ gewählt werden
- ist oft aufwendig zu berechnen

---