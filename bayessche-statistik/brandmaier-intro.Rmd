---
title: "Einführung in die Bayessche Statistik"
subtitle: "<br/>Probelehrveranstaltung"
author: "Andreas Brandmaier"
institute: ""
#date: "`r Sys.Date()`"
dat: "2021-02-11"
output:
  xaringan::moon_reader:
    css: [default,  "extra.css","sydney.css", "sydney-fonts.css"]
#    css: [robot]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r xaringanExtra, echo=FALSE, message=FALSE, warning=FALSE}
#xaringanExtra::use_xaringan_extra(c( "animate_css", "tachyons"))

library(here)
library(tidyverse)
#source(here("R/scripts.R"))
source("R/scripts.R")
```

# Ziel der Inferenzstatistik

.contentbox-blue[Das Anliegen einer jeden wissenschaftlichen Aussage ist, dass sie möglichst allgemeingültig sein soll]

Um aus Daten einer begrenzten Anzahl Personen auf eine große Anzahl von Menschen schließen kann, befassen wir uns mit der Inferenzstatistik

Typische Fragen in der Psychologie sind:

- Wirkt eine neue Therapieform B besser als eine Therapieform A?
- Gibt es einen Zusammenhang zwischen Computerspielen und Gewalt bei Jugendlichen?
- Werden attraktivere Menschen als erfolgreicher eingeschätzt?

---

# Frequentistische Inferenz

.read_more[Beispiel TODO]
Typischerweise zwei Aufgaben: Schätzen und Testen

```{r echo=FALSE, message=FALSE, result='hide', warning=FALSE}
source("R/t-verteilung.R")
```

---

# Missverstaendnisse in der frequentistischen Inferenz

Die frequentistische Inferenz wird oft falsch verstanden. Typische Denkfehler sind, zu glauben, ...

- dass ein nicht-signifikanter Unterschied zwischen zwei Gruppen bedeutet, dass deren Mittelwerte in Wahrheit gleich sind (richtig ist: es ist keine Aussage möglich)

- dass der $p$-Wert die Wahrscheinlichkeit der Nullhypothese angibt (richtig: es gibt an, wie (un)glaubwürdig das Ergebnis (oder ein extremeres) unter der Nullhypothese ist)

Unbefriedigend ist:

- bei einem nicht-signifikantem Ergebnis, ist "keine Aussage" unbefriedigend, da die gesammelte Information nicht genutzt ist

---

# Bedingte Wahrscheinlichkeiten

Die .emph[bedingte Wahrscheinlichkeit], dass A eintritt, wenn B bereits eingetreten ist, lässt sich aus dem Verhältnis der Wahrscheinlichkeit des gemeinsamen Auftretens von A und B und der Wahrscheinlichkeit von B bestimmen:

<!--\newcommand{ba}{\color{blue}{A}}-->

.largemath[
$$P \left( \color{blue}{A} | B \right) = \frac{ P\left( A \cap B \right) }{ P\left(B \right) } $$
]

Beispiele:

$P\left(\textrm{Die Straße ist nass} | \textrm{es hat geregnet}\right) \approx 1$
$P\left(\textrm{es hat geregnet} | \textrm{die Straße ist nass}\right) < 1$

---


# Der Satz von Bayes

Bayesianische Ansätze folgen der folgenden charakteristischen Struktur, die sich aus der bedingten Wahrscheinlichkeit ableiten lassen:

.largemath[
$$P \left( A | B \right) = \frac{ P\left(B | A \right) \times  P\left( B \right)   }{P\left(A \right)  } $$
]

---

# Vampirismus und der Satz von Bayes &#129415;

$$P\left( Vampir | + \right) = \frac{ P\left( + | Vampir \right) \times  P\left(Vampir \right)   }{  P\left( + \right)  } $$
- $P \left( + | Vampir \right) = .8$
- $P \left( Vampir \right) = .XX$
- $P \left( + \right) = XXX$

Erlaubt uns den Schluss:

$P\left( Vampir | + \right) =$

---

class: segue-large-red

.bigfont[
Aber Achtung: Die Anwendung des Satzes von Bayes macht noch keinen Bayesianer aus Ihnen!
]
---

# Bayesianischer Ansatz

.read_more[Idee:] Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen

.largermath[
$$ P\left( Modell | Daten \right) = \frac{ P\left(Daten | Modell\right) \cdot P\left( Modell \right) }{ P\left( Daten \right) } $$
]




---

# Bayesianischer Ansatz

.hide[Idee: Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen
]

.largermath[
$$ \underbrace{P\left( Modell | Daten \right)}_{Posterior} = \frac{ \overbrace{P\left(Daten | Modell\right)}^{Likelihood} \cdot \overbrace{P\left( Modell \right)}^{Prior} }{ P\left( Daten \right)  } $$
]


.read_more[Der Nenner P(Daten) ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

class:segue-large-red

.bigfont[
Aber Moment... was ist denn die _Wahrscheinlichkeit einer Hypothese_ überhaupt?
]

---


# Frequentistische Postulate

(nochmal zurück zum Start)

- F1: Wahrscheinlichkeiten beziehen sich auf relative Häufigkeit von Ereignisse bei einer großen Anzahl gleicher, wiederholter Durchführungen eines Zufallsexperiments. Wahrscheinlichkeiten sind objektive Eigenschaften der echten Welt.

- F2: Die wahren Parameter sind unbekannte Konstanten. Weil sie nicht veränderlich sind, kann man keine probabilistischen Aussagen über sie treffen.

- F3:


.citation[frei nach 'All of Statistics' von L. Wassermann]
---

# Wahrscheinlichkeiten

.pull-left[

.content-box-blue[Frequentistische Perspektive]

Aus klassischer Sicht ist es inakzeptabel Modellparameter durch Wahrscheinlichkeitsverteilungen zu repräsentieren, weil sie als konstant angenommen werden. Nur die beobachteten Daten sind zufällig gezogen und dürfen durch Wahrscheinlichkeitsverteilungen beschrieben werden.
]

.pull-right[

.content-box-gray[Bayesianische Perspektive]

Jedes Element des Modells, das mit Unsicherheit behaftet ist, kann durch eine Wahrscheinlichkeitsverteilung abgebildet werden, die den Grad der Unsicherheit abbildet, insbesondere Modellparameter.
]


---


# Wahrscheinlichkeitsbegriff

.pull-left[

.content-box-blue[Frequentistische Perspektive]

Wahrscheinlichkeit ist die .highlight[relative Häufigkeit] (Frequenz) eines Ereignis bei
sehr häufiger (unendlich oft) Wiederholung

]

.pull-right[

.content-box-gray[Bayesianische Perspektive]

Wahrscheinlichkeit ist der Ausdruck eines .highlight[Grad der Überzeugung] (_"degree of belief"_)

]

.pull-down[

Obwohl wir dieselbe Axiomatik der Wahrscheinlichkeitsrechnung nutzen, ist dies ein entscheidender philosophischer Unterschied. 

]

---

# Prior, Likelihood, und Posterior

.pull-left[
Beispiel: Statistisches Modell mit einem Parameter (z.B., Mittlerer IQ)

- Prior: Glaubwürdigkeit aller möglichen Mittelwerte
- Likelihood: Plausibilität gegeben den Daten
- Posterior: Glaubwürdigkeit nach Beobachtung der Daten
]

.pull-right[

```{r fig.width=6, fig.height=6, echo=FALSE, message=FALSE}
source("R/schematic-bayes.R")
```
]
---

# Wann spielt der Prior eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]

.pull-right[
```{r fig.width=7, fig.height=7, echo=FALSE}
prior_sd <- 35
source("R/schematic-bayes.R")
```
]
---

# Wann spielt der Prior eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]
.pull-right[
```{r fig.width=7, fig.height=7, echo=FALSE}
prior_sd <- 15
nfakefac <- 20
source("R/schematic-bayes.R")
```
]

---

# Woher kommt der Prior?

Es gibt verschiedene Wege, Priors zu wählen:

- Uninformierte Priors
- Sinnvolle Beschränkungen des Parameterraums (z.B. Nicht-Negativität)
- Vorwissen
- Expertenmeinungen (elicited priors)
- Bequeme Prior-Verteilungen (conjugate priors)
---

# Beispiel: Beschränkung

```{r echo=FALSE}
prior.demo(1)
```

---

# Beispiel: Informierter Prior

```{r echo=FALSE}
prior.demo(2)
```

---

# Beispiel: Eruierte Prior

![](Screenshot 2021-01-26 at 14.45.02.png)

.citation[Dallow et al. "Better Decision Making in Drug Development Through Adoption of Formal Prior Elicitation"]
---

# Posterior

Das Ergebnis einer Schätzung ist der Posterior:

.pull-left[
- Für jeden möglichen Parameterwert erhalten wir eine Wahrscheinlichkeit

– Enthält nicht nur einen einzelnen Punktschätzer (z.B. Effektstärke), sondern auch Informationen über die Genauigkeit / (Un-)Sicherheit unserer Schätzung

- Posterior ist die Verteilung über all möglichne Parameter gleichzeitig
]
.pull-right[

```{r}
source("R/posterior.R")
```

]
---

class: segue-large-gold

.bigfont[
Und was ist daran so kompliziert?
]
---

# Bayessche Integrale

Für viele Bayessche Anwendung benötigen wir Integrale, z.B., für

-   Berechnung der Evidenz in der Posterior-Verteilung:

$$P\left(\theta | D \right) = \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ \int{ P\left(\right) P\left(\right)} d\theta } $$

- Randverteilung der Prior
- Punkt- und Intervallschätzer, wie z.B. Maximum-A-Posteriori or Credibility Region
- Modellvergleich mit dem Bayes Faktor

---

# Bayesianische Integrale lösen

Es existieren verschiedene Ansätze:

- Analytische Lösungen mit .emph[konjugierten Priors]

  Bestimmte statistische Modelle haben Priors, die zu Posteriors führen, die aus derselben Verteilungsfamilie stammen
  
- Approximationen wie bspw. .emph[Variational Bayes]

  Finde einfache Verteilungen, die den wahren Posterior annähern
  
- .emph[Monte Carlo Markov Chains] (MCMC)

  Anstatt exakt zu rechnen, ziehen wir zufällig aus der Posteriorverteilung und rechnen mit den Samples weiter

---  

# Ein Beispiel - Mittelwerte schätzen

.question[Fragestellung: ] Haben Studierende aus Potsdam einen höheren IQ als 100?

Die Stichprobe $y_1,\ldots, y_{10}$ sei:

```{r}
set.seed(234)
iqdat <- tibble(x= rnorm(10,mean=110,sd=10))
ggplot(iqdat,aes(y=x))+geom_boxplot()+ geom_point(x=0,size=4)+ylab("IQ")
```

Dabei sei $\mu$ der unbekannte wahre Mittelwert der Potsdamer Studierenden

Unsere Modellannahme sei:

$$Y_i = \mu + \epsilon_i$$

- $y_i$ sind Realisierungen einer Zufallsvariable $Y_i$
- $\mu_i$ ist der wahre aber unbekannte Mittelwert
- $\epsilon_i$ sind unabhängige Zufallsvariablen mit Mittelwert 0 und Varianz $\sigma^2$, die sowohl wahre Unterschiede als auch Messfehler widerspiegeln

---

Frequentistischer Ansatz:

- Unter allen möglichen Normalverteilungen $N(m,s^2)$ mit Mittelwert $m$ uns Varianz $s^2$, wähle die, die am plausibelsten die Daten erzeugt hat:

```{r}

dist_means <- c(80,mean(x), 120)
dist_sds <- c(10, sqrt(var(x)), 10)

df <- data.frame(x=seq(60,140,.1))
for (i in 1:3) {
#y1 <- dnorm(x, mean = dis)
  df[,paste0("y",i)] <- dnorm(df$x, dist_means[i], dist_sds[i])
}

df %>% pivot_longer(-1) %>% 
  ggplot(aes(x=x,y=value,group=name,color=name,fill=name))+
  geom_line()+geom_ribbon(aes(ymin=0,ymax=value))
  
sum(log(dnorm(iqdat$x,mean = 80, sd=10)))

```

---

# Zusammenfassung

Die Bayessche Statistik 

- benutzt Wahrscheinlichkeiten um Unsicherheiten zu beschreiben
- erfordert die Spezifikation von Prior-Verteilungen aller Modellparameter
- ist oft aufwendig zu berechnen

---

# Inkrementelles Lernen: Bayesian Updating

Der Bayesianische Ansatz entspricht der Idee von Wissenschaft als kumulativem Prozeß

Beispiel: Wir möchten die Prävalenz depressiver Erkrankungen in der Bevölkerung schätzen

- Wahrscheinlichkeitsmodell: Binomialverteilung (zur Erinnerung: Diese modelliert das Ergebnis einer Reihe von Münzwürfen), gesucht ist die Wahrscheinlichkeit, eine depressive Erkrankung zu beobachten

- konjugierte Priorverteilung: Betaverteilung mit zwei Parametern

---

# Bayesian Updating

```{r, echo=FALSE, eval=TRUE, fig.width=12, fig.height=6,out.width="120%"}
# beta-binomial model
betabinomial_plot <- function(a1=1,b1=1,a2=1,b2=2) {
x<-seq(0,1,.01)
prior <- dbeta(x, shape1=a1, shape2=b1)
posterior <- dbeta(x, shape1=a2, shape2=b2)

df <- data.frame(x,Prior=prior, Posterior=posterior)

df %>% pivot_longer(Prior:Posterior,names_to = "Verteilung") %>%
  ggplot(aes(x=x,y=value,group=Verteilung,lty=Verteilung,color=Verteilung))+
  geom_line(lwd=2)+
  ggthemes::theme_clean()+
  xlab("Prävalenz Depression")+
  ylab("Plausibilität")
}


b1 <- betabinomial_plot(1,1,2,1) + ggtitle("1 Ziehung")+theme(legend.box = "horizontal")#+theme(legend.position="none")
b2 <- betabinomial_plot(2,1,2,2)+ ggtitle("2 Ziehungen")#+theme(legend.position="none")
b3 <- betabinomial_plot(2,2,2,3) + ggtitle("3 Ziehungen")#+theme(legend.position="none")
b4 <- betabinomial_plot(2,3,5,45)+ ggtitle("50 Ziehungen")

legend <- g_legend(b1)

b1 <- b1 + theme(legend.position="none")
b2 <- b2 + theme(legend.position="none")
b3 <- b3 + theme(legend.position="none")
b4 <- b4 + theme(legend.position="none")

library(patchwork)
(b1 | b2 | b3 | b4 ) / legend
```

---
