---
title: "Einführung in die Bayessche Statistik"
subtitle: "<br/>Probelehrveranstaltung"
author: "Andreas Brandmaier"
institute: ""
#date: "`r Sys.Date()`"
date: "2021-02-11"
output:
  xaringan::moon_reader:
    css: [default,  "extra.css","sydney.css", "sydney-fonts.css"]
#    css: [robot]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r xaringanExtra, echo=FALSE, message=FALSE, warning=FALSE}
#xaringanExtra::use_xaringan_extra(c( "animate_css", "tachyons"))

library(here)
library(tidyverse)
library(ggx)
#source(here("R/scripts.R"))
source("R/scripts.R")
```

# Ziel der Inferenzstatistik

.hide[fill]
.hide[fill]

.larger[

.read_more[Um aus Daten einer begrenzten Anzahl Personen auf eine große Anzahl von Menschen schließen kann, befassen wir uns mit der Inferenzstatistik.] 

.read_more[Allgemeingültigkeit]

.read_more[Quantifizierung der Unsicherheit]

]

---

# Aussagen über die Unsicherheit

<!--.read_more[Typische Fragen in der Psychologie sind:]

 - Wirkt eine neue Therapieform B besser als eine Therapieform A?
- Gibt es einen Zusammenhang zwischen Computerspielen und Gewalt bei Jugendlichen?
- Werden attraktivere Menschen als erfolgreicher eingeschätzt? -->

<br><br>

.med[Typische Aussagen, die wir als Wissenschaftler gerne für unsere empirischen Effektstärken treffen wollen:]

--

- Das Vakkzin von BioNTech/Pfizer schützt mit sehr hoher Wahrscheinlichkeit besser vor einer COVID19-Erkrankung als der Wirkstoff von AstraZeneca

--

- Studierende in Potsdam haben mit großer Wahrscheinlichkeit einen höheren IQ als der Bevölkerungsdurchschnitt

---


# Ein Beispiel - Mittelwerte schätzen

.emph[Fragestellung: ] Haben Studierende in Potsdam im Mittel einen höheren IQ als 100?

--

.pull-left[

Die Stichprobe (n=10) sei:

```{r iq, eval=TRUE, echo=FALSE, fig.height=5,warning=FALSE,results="hide",message=FALSE}
set.seed(234)
iqdat <- tibble(x= rnorm(10,mean=110,sd=10))
ggplot(iqdat,aes(x=x))+geom_boxplot()+ geom_point(y=0,size=8)+xlab("IQ")+
  theme(text=element_text(size=25))+
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())+
  xlim(60,140)
```
]
.pull-right[

Unsere Modellannahme sei:

IQ-Test Ergebnisse sind normalverteilt mit wahrem Mittelwert $\mu$ und wahrer Varianz $\sigma^2$.

.read_more[Dabei] sei $\mu$ der unbekannte wahre Mittelwert der Potsdamer Studierenden

]

---

# Frequentistischer Ansatz:

.pull-left[
## Schätzen

Unter allen möglichen Normalverteilungen, wähle die, die am plausibelsten die Daten erzeugt hat:

```{r echo=FALSE, fig.height=4, fig.width=6, echo=FALSE}
source("R/likelihood.R")

```

Der Stichprobenmittelwert ist hier $m=$ `r round(mean(iqdat$x))`.
]

--

.pull-right[

## Testen

Wie plausibel sind die Beobachtungen (oder extremer) unter einem Nullmodell?

```{r echo=FALSE, fig.height=4, fig.width=6, results="hide", warning=FALSE}
source("R/t-verteilung.R")
```

Der p-Wert ist $p=$ `r round(pval,2)`.
]

---

# Frequentistischer Ansatz

.pull-left[
## Schätzen

.largermath[
$$\arg \max_\theta P\left( D | \theta\right)$$
]



]

.pull-right[
## Testen

.largermath[

$$P\left(D | \theta_0 \right) $$
]
]

<br><br><br><br>

.med[
.read_more[Wir halten fest, dass beide Ansätze auf .emph[bedingten Wahrscheinlichkeiten] basieren]. Und zwar auf der .emph[Datenwahrscheinlichkeit].
]
---

# Missverständnisse in der frequentistischen Inferenz

.med[Typische Irrtümer:]

--

- .emph[Falsch]: Der p-Wert ist die Wahrscheinlichkeit der Null-Hypothese. Bsp.: Wir glauben mit großer Wahrscheinlichkeit, dass die Nullhypothese (Studierende haben einen mittleren IQ von 100) falsch ist, wenn $p < 0.05$.

--

- Dabei reden wir aber über $p(\theta_0 | D)$ während der p-Wert aber aus der Funktion $p(D | \theta_0)$ berechnet wird 

--

- "Studierende in Potsdam haben mit großer Wahrscheinlichkeit einen höheren IQ als der Bevölkerungsdurchschnitt"

- Das ist eine Aussage über $p(H_1 | D)$, aber wir arbeiten nur mit p-Werten der Funktion $p(D | H_0)$

--

Offenbar wollen wir oft Aussagen über die .emph[Parameter- oder Hypothesenwahrscheinlichkeit] $P\left(\theta | D \right)$ machen, nutzen zur Inferenz aber die .emph[Datenwahrscheinlichkeit] $P\left(D | \theta \right)$.

---

class: segue-large-red

.bigfont[
Idee: Können wir $P\left(\theta | D \right)$ aus $P\left(D | \theta \right)$ berechnen?
]

---


# Der Satz von Bayes

Bayesianische Ansätze folgen der folgenden charakteristischen Struktur, die sich aus der bedingten Wahrscheinlichkeit ableiten lassen:

.largemath[
$$P \left( A | B \right) = \frac{ P\left(B | A \right) \times  P\left( A \right)   }{P\left(B \right)  } $$
]

---

# Bayesianischer Ansatz

.read_more[Idee:] Ausgehend von der bekannten Likelihood $P\left( Daten | \theta\right)$, nutzen wir den Satz von Bayes, um $P\left( \theta | Daten \right)$ zu berechnen

.largermath[
$$ P\left( \theta | Daten \right) = \frac{ P\left(Daten | \theta\right) \cdot P\left( \theta \right) }{ P\left( Daten \right) } $$
]


.hide[Der Nenner $P(Daten)$ ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

# Bayesianischer Ansatz

.hide[Idee: Ausgehend von der bekannten Likelihood $P\left( Daten | \theta \right)$, nutzen wir den Satz von Bayes, um $P\left( \theta | Daten \right)$ zu berechnen
]

.largermath[
$$ \underbrace{P\left( \theta | Daten \right)}_{Posterior} = \frac{ \overbrace{P\left(Daten | \theta\right)}^{Likelihood} \cdot \overbrace{P\left( \theta \right)}^{Prior} }{ P\left( Daten \right)  } $$
]


.read_more[Der] Nenner $P(Daten)$ ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten


---

#  &#129415; Vampirismus und der Satz von Bayes


```{r echo=FALSE}
# adapted from Richard McElreath's fantastic book
PrPV <- .95
PrPM <- 0.01
PrV <- 0.001
PrP <- PrPV*PrV + PrPM*(1-PrV)

PrVP <- PrPV*PrV/PrP
```

.emph[Bedingte Wahrscheinlichkeiten sind manchmal überraschend]. Beispiel: Bekannt sei ein Test, der mit einer Erfolgschance von `r round(PrPV*100)`% Vampirismus detektiert. Wie hoch ist die Chance, bei positivem Ergebnis, ein Vampir zu sein?

--

.med[
$$P\left( Vampir | + \right) = \frac{ P\left( + | Vampir \right) \times  P\left(Vampir \right)   }{  P\left( + \right)  } $$
]

--

- $P \left( + | Vampir \right) =$ `r PrPV`
- $P \left( Vampir \right) =$ `r PrV`
- $P \left( + \right) =$  `r PrP`

Erlaubt uns den (.emph[immer noch frequentistischen]) Schluss:

- $P \left( Vampir | + \right) =$ `r round(PrVP,2)`

.citation[R. McElreath, Statistical Rethinking]

---

class:segue-large-red

.bigfont[
Aber Moment... was ist denn die _Wahrscheinlichkeit eines Parameters, eines Modells_ oder _einer Hypothese_ überhaupt?
]

---


# Frequentistische Postulate

(nochmal zurück zum Start)

- Wahrscheinlichkeiten beziehen sich auf .emph[relative Häufigkeit] von Ereignisse bei einer großen Anzahl gleicher, wiederholter Durchführungen eines Zufallsexperiments. Wahrscheinlichkeiten sind objektive Eigenschaften der echten Welt.

--

- Die wahren .emph[Parameter sind unbekannte Konstanten]. Weil sie nicht veränderlich sind, kann man keine probabilistischen Aussagen über sie treffen.


---


# Wahrscheinlichkeitsbegriff

.pull-left[

## Frequentistische Perspektive

Wahrscheinlichkeit ist die .emph[relative Häufigkeit] (Frequenz) eines Ereignis bei
sehr häufiger (unendlich oft) Wiederholung

]

--

.pull-right[

## Bayesianische Perspektive

Wahrscheinlichkeit ist der Ausdruck eines .emph[Grad der Überzeugung] (_"degree of belief"_)

]

.pull-down[

Obwohl wir dieselbe Axiomatik der Wahrscheinlichkeitsrechnung nutzen, ist dies ein entscheidender philosophischer Unterschied. 

]

---

# Prior, Likelihood, und Posterior

.pull-left[
Beispiel: Statistisches Modell mit einem Parameter (z.B., Mittlerer IQ)

- .blue[Prior]: Glaubwürdigkeit aller möglichen Mittelwerte
- .red[Likelihood]: Plausibilität gegeben den Daten
- .green[Posterior]: Glaubwürdigkeit nach Beobachtung der Daten

.larger[
.green[Posterior] $\propto$ .red[Likelihood] $\times$ .blue[Prior]
]

]

.pull-right[

```{r echo=FALSE, message=FALSE}
source("R/schematic-bayes.R")
```
]

---

# Posterior

Das Ergebnis einer Schätzung ist der Posterior:

.pull-left[

- Enthält nicht nur einen einzelnen Punktschätzer (z.B. Effektstärke)

- Für jeden möglichen Parameterwert erhalten wir eine Wahrscheinlichkeit

- Spezifiziert vollständig unsere Unsicherheit

- Erlaubt (endlich!) Aussagen wie, das 95%-Intervall (.emph[credibility interval]) enthält zu 95% den wahren Parameter
]

.pull-right[

```{r echo=FALSE, warning=FALSE}
source("R/posterior.R")
```

]

---


class:segue-large-red

.bigfont[
Woher kommt der _Prior_ überhaupt?
]

---

# Beispiel: Informierter Prior

```{r echo=FALSE, fig.width=12, fig.height=6}
source("R/prior_demo.R")
prior.demo(2)
```

---

# Woher kommt der Prior?

Es gibt verschiedene Wege, Priors zu wählen:

- Flache und uninformierte Priors
- Sinnvolle Beschränkungen des Parameterraums (z.B. Nicht-Negativität einer Reaktionszeit)
- Vorwissen
- Expertenmeinungen (_elicited priors_)


---

# Wann spielt der Prior (k)eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]

.pull-right[
```{r fig.width=7, fig.height=7, echo=FALSE}
prior_sd <- 35
source("R/schematic-bayes.R")
```
]
---

# Bayessche Integrale

Für viele Bayessche Anwendung benötigen wir Integrale, z.B., für

-   Berechnung der Evidenz in der Posterior-Verteilung:

$$P\left(\theta | D \right) =  \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ \int{ P\left( D | \theta  \right) P\left(\theta \right)} d\theta } $$
- Punkt- und Intervallschätzer, wie z.B. Mittelwert oder Glaubwürdigkeitsintervall
- Randverteilung einzelner Parameter
- Modellvergleich mit dem .emph[Bayes Faktor]

---

# Bayesianische Integrale lösen

- Prominenter Ansatz mittels .emph[Monte Carlo Markov Chains] (MCMC)

- Anstatt exakt zu rechnen, ziehen wir zufällig aus der Posteriorverteilung und rechnen mit der Zufallsstichprobe näherungsweise weiter

```{r echo=FALSE, fig.height=4, fig.width=12}
source("R/rejection-sampler.R")
```

---


# Zusammenfassung

Die Bayessche Statistik 

- benutzt Wahrscheinlichkeiten um Unsicherheiten vollständig zu beschreiben
- erlaubt Aussagen über die Parameter- und Hypothesenwahrscheinlichkeit anstatt über die Datenwahrscheinlichkeiten
- erfordert die Spezifikation von Prior-Verteilungen aller Modellparameter
- ist oft aufwendig zu berechnen, aber verschiedene praktische Lösungen existieren

---


# Testen mit dem Bayes Factor

- Bayesianer formulieren eine explizite Alternative, gegen die getestet werden kann, bspw: 
    - $H_1$: Der mittlere IQ ist 0
    - Die Prior-Verteilung betrifft dann nur noch die übrigen Parameter, hier, die Varianz.

- Testen wird als Modellvergleich durchgeführt:

$$BF_{10}=\frac{P\left(D | H_1\right)}{P\left(D | H_0\right)} $$
- Dies korrespondiert zu der Logik des Likelihood-Ratio Tests unter Berücksichtigung der kompletten Unsicherheit im Posterior
---

class: segue-large-gold

.bigfont[
Und was ist daran so kompliziert?
]
---