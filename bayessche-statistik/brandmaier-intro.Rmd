---
title: "Einführung in die Bayessche Statistik"
subtitle: "<br/>Probelehrveranstaltung"
author: "Andreas Brandmaier"
institute: ""
#date: "`r Sys.Date()`"
dat: "2021-02-11"
output:
  xaringan::moon_reader:
    css: [default,  "extra.css","sydney.css", "sydney-fonts.css"]
#    css: [robot]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---

```{r xaringanExtra, echo=FALSE, message=FALSE, warning=FALSE}
#xaringanExtra::use_xaringan_extra(c( "animate_css", "tachyons"))

library(here)
library(tidyverse)
library(ggx)
#source(here("R/scripts.R"))
source("R/scripts.R")
```

# Ziel der Inferenzstatistik

.hide[fill]
.hide[fill]

.larger[

.read_more[Um aus Daten einer begrenzten Anzahl Personen auf eine große Anzahl von Menschen schließen kann, befassen wir uns mit der Inferenzstatistik.] 

.read_more[Allgemeingültigkeit]

.read_more[Quantifizierung der Unsicherheit]

]

<!--.read_more[Typische Fragen in der Psychologie sind:]

 - Wirkt eine neue Therapieform B besser als eine Therapieform A?
- Gibt es einen Zusammenhang zwischen Computerspielen und Gewalt bei Jugendlichen?
- Werden attraktivere Menschen als erfolgreicher eingeschätzt? -->

---


# Ein Beispiel - Mittelwerte schätzen

.question[Fragestellung: ] Haben Studierende aus Potsdam einen höheren IQ als 100?

.pull-left[

Die Stichprobe $y_1,\ldots, y_{10}$ sei:

```{r iq, eval=TRUE, echo=FALSE, fig.height=5,warning=FALSE,results="hide",message=FALSE}
set.seed(234)
iqdat <- tibble(x= rnorm(10,mean=110,sd=10))
ggplot(iqdat,aes(y=x))+geom_boxplot()+ geom_point(x=0,size=4)+ylab("IQ")+
  gg_("set y-axis font size to 20")
```
]
.pull-right[

Dabei sei $\mu$ der unbekannte wahre Mittelwert der Potsdamer Studierenden

Unsere Modellannahme sei:

$$Y_i = \mu + \epsilon_i$$

- $y_i$ sind Realisierungen einer Zufallsvariable $Y_i$
- $\mu_i$ ist der wahre aber unbekannte Mittelwert
- $\epsilon_i$ sind unabhängige Zufallsvariablen mit Mittelwert 0 und Varianz $\sigma^2$, die sowohl wahre Unterschiede als auch Messfehler widerspiegeln
]

---

# Frequentistischer Ansatz:

.pull-left[
## Schätzen

- Unter allen möglichen Normalverteilungen $N(m,s^2)$ mit Mittelwert $m$ uns Varianz $s^2$, wähle die, die am plausibelsten die Daten erzeugt hat:

```{r echo=FALSE, fig.height=4, fig.width=6}
source("R/likelihood.R")

```

--

]

.pull-right[
## Testen

Wie plausibel sind die Beobachtungen (oder extremer) unter einem Nullmodell?

```{r echo=FALSE, fig.height=5, fig.width=5, results="hide", warning=FALSE}
source("R/t-verteilung.R")
```
]

---

# Frequentistischer Ansatz

.pull-left[
## Schätzen

.largermath[
$$\arg \max_\theta P\left( D | M_\theta \right)$$
]



]

.pull-right[
## Testen

.largermath[

$$P\left(D | M_0 \right) $$
]
]

---

# Missverständnisse in der frequentistischen Inferenz

Dennoch sind wir sind wir oft versucht, Aussagen über $P\left(M | D \right)$ zu treffen:

- dass ein nicht-signifikanter Unterschied bedeutet, dass der Mittelwerte mit hoher Wahrscheinlichkeit gleich 100 ist (richtig ist: es ist keine Aussage möglich)

- dass der $p$-Wert die Wahrscheinlichkeit der Nullhypothese angibt (richtig: es gibt an, wie (un)glaubwürdig das Ergebnis (oder ein extremeres) unter der Nullhypothese ist)

- dass das Konfidenzintervall mit 95% Wahrscheinlichkeit den wahren Wert enthält (95% unserer Konfidenzintervalle enthalten den wahren Wert)

---

class: segue-large-red

.bigfont[
Idee: Können wir $P\left(M | D \right)$ aus $P\left(D | M \right)$ berechnen?
]

---

# Bedingte Wahrscheinlichkeiten

Die .emph[bedingte Wahrscheinlichkeit], dass A eintritt, wenn B bereits eingetreten ist, lässt sich aus dem Verhältnis der Wahrscheinlichkeit des gemeinsamen Auftretens von A und B und der Wahrscheinlichkeit von B bestimmen:

<!--\newcommand{ba}{\color{blue}{A}}-->

.largemath[
$$P \left( A | B \right) = \frac{ P\left( A \cap B \right) }{ P\left(B \right) } $$
]

Beispiele:

- $P\left(\textrm{Die Straße ist nass} | \textrm{es hat geregnet}\right) \approx 1$
- $P\left(\textrm{es hat geregnet} | \textrm{die Straße ist nass}\right) < 1$

---


# Der Satz von Bayes

Bayesianische Ansätze folgen der folgenden charakteristischen Struktur, die sich aus der bedingten Wahrscheinlichkeit ableiten lassen:

.largemath[
$$P \left( A | B \right) = \frac{ P\left(B | A \right) \times  P\left( A \right)   }{P\left(B \right)  } $$
]

---

# Vampirismus und der Satz von Bayes &#129415;


```{r echo=FALSE}
# adapted from Richard McElreath's fantastic book
PrPV <- .95
PrPM <- 0.01
PrV <- 0.001
PrP <- PrPV*PrV + PrPM*(1-PrV)

PrVP <- PrPV*PrV/PrP
```

Bekannt sei ein Test, der mit einer Erfolgschance von `r round(PrPV*100)`% Vampirismus detektiert. Wie hoch ist die Chance, bei positivem Ergebnis, ein Vampir zu sein?

$$P\left( Vampir | + \right) = \frac{ P\left( + | Vampir \right) \times  P\left(Vampir \right)   }{  P\left( + \right)  } $$

- $P \left( + | Vampir \right) =$ `r PrPV`
- $P \left( Vampir \right) =$ `r PrV`
- $P \left( + \right) =$  `r PrP`

Erlaubt uns den Schluss:

- $P \left( Vampir | + \right) =$ `r round(PrVP,2)`

---

# Bayesianischer Ansatz

.read_more[Idee:] Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen

.largermath[
$$ P\left( Modell | Daten \right) = \frac{ P\left(Daten | Modell\right) \cdot P\left( Modell \right) }{ P\left( Daten \right) } $$
]


.hide[Der Nenner P(Daten) ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

# Bayesianischer Ansatz

.hide[Idee: Ausgehend von der bekannten Likelihood $P\left( Daten | Modell \right)$, nutzen wir den Satz von Bayes, um $P\left( Modell | Daten \right)$ zu berechnen
]

.largermath[
$$ \underbrace{P\left( Modell | Daten \right)}_{Posterior} = \frac{ \overbrace{P\left(Daten | Modell\right)}^{Likelihood} \cdot \overbrace{P\left( Modell \right)}^{Prior} }{ P\left( Daten \right)  } $$
]


.read_more[Der Nenner $P(Daten)$ ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

class:segue-large-red

.bigfont[
Aber Moment... was ist denn die _Wahrscheinlichkeit einer Hypothese_ überhaupt?
]

---


# Frequentistische Postulate

(nochmal zurück zum Start)

- F1: Wahrscheinlichkeiten beziehen sich auf relative Häufigkeit von Ereignisse bei einer großen Anzahl gleicher, wiederholter Durchführungen eines Zufallsexperiments. Wahrscheinlichkeiten sind objektive Eigenschaften der echten Welt.

- F2: Die wahren Parameter sind unbekannte Konstanten. Weil sie nicht veränderlich sind, kann man keine probabilistischen Aussagen über sie treffen.

- F3: Statistische Prozeduren werden so entworfen, dass sie Langzeit-Garantien geben. Beispielsweise enthalten 95 von 100 Konfidenzintervalle enthalten im Mittel den wahren Wert.


.citation[frei nach 'All of Statistics' von L. Wassermann]
---


# Wahrscheinlichkeitsbegriff

.pull-left[

.content-box-blue[Frequentistische Perspektive]

Wahrscheinlichkeit ist die .highlight[relative Häufigkeit] (Frequenz) eines Ereignis bei
sehr häufiger (unendlich oft) Wiederholung

]

.pull-right[

.content-box-gray[Bayesianische Perspektive]

Wahrscheinlichkeit ist der Ausdruck eines .highlight[Grad der Überzeugung] (_"degree of belief"_)

]

.pull-down[

Obwohl wir dieselbe Axiomatik der Wahrscheinlichkeitsrechnung nutzen, ist dies ein entscheidender philosophischer Unterschied. 

]

---

# Prior, Likelihood, und Posterior

.pull-left[
Beispiel: Statistisches Modell mit einem Parameter (z.B., Mittlerer IQ)

- .blue[Prior]: Glaubwürdigkeit aller möglichen Mittelwerte
- .red[Likelihood]: Plausibilität gegeben den Daten
- .green[Posterior]: Glaubwürdigkeit nach Beobachtung der Daten
]

.pull-right[

```{r fig.width=7, fig.height=7, echo=FALSE, message=FALSE}
source("R/schematic-bayes.R")
```
]
---

# Wann spielt der Prior eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]

.pull-right[
```{r fig.width=7, fig.height=7, echo=FALSE}
prior_sd <- 35
source("R/schematic-bayes.R")
```
]
---


class:segue-large-red

.bigfont[
Woher kommt der _Prior_ überhaupt?
]

# Beispiel: Beschränkung

```{r echo=FALSE, fig.width=12, fig.height=6}
source("R/prior_demo.R")
prior.demo(1)
```

---

# Beispiel: Informierter Prior

```{r echo=FALSE, fig.width=12, fig.height=6}
prior.demo(2)
```

---

# Woher kommt der Prior?

Es gibt verschiedene Wege, Priors zu wählen:

- Flache und uninformierte Priors
- Sinnvolle Beschränkungen des Parameterraums (z.B. Nicht-Negativität)
- Vorwissen
- Expertenmeinungen (elicited priors)

---

# Posterior

Das Ergebnis einer Schätzung ist der Posterior:

.pull-left[
- Für jeden möglichen Parameterwert erhalten wir eine Wahrscheinlichkeit

- Enthält nicht nur einen einzelnen Punktschätzer (z.B. Effektstärke), sondern auch Informationen über die Genauigkeit / (Un-)Sicherheit unserer Schätzung

- Spezifiziert vollständig unsere Unsicherheit

- Erlaubt Aussagen wie, das 95%-Intervall (HDI) enthält zu 95% den wahren Parameter
]

.pull-right[

```{r echo=FALSE, warning=FALSE}
source("R/posterior.R")
```

]
---

class: segue-large-gold

.bigfont[
Und was ist daran so kompliziert?
]
---

# Bayessche Integrale

Für viele Bayessche Anwendung benötigen wir Integrale, z.B., für

-   Berechnung der Evidenz in der Posterior-Verteilung:

$$P\left(\theta | D \right) = \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ \int{ P\left( D | \theta  \right) P\left(\theta \right)} d\theta } $$
- Punkt- und Intervallschätzer, wie z.B. Mean oder Credibility Region

$$\hat{\mu} = \int \theta \cdot P\left(\theta | D \right)  d\theta $$
  

- Randverteilung einzelner Parameter
- Modellvergleich mit dem _emph[Bayes Faktor]

---

# Bayesianische Integrale lösen

Es existieren verschiedene Ansätze:

.read_more[] Analytische Lösungen mit .emph[konjugierten Priors]

  Bestimmte statistische Modelle haben Priors, die zu Posteriors führen, die aus derselben Verteilungsfamilie stammen
  
- Approximationen wie bspw. .emph[Variational Bayes]

  Finde einfache Verteilungen, die den wahren Posterior annähern
  
- .emph[Monte Carlo Markov Chains] (MCMC)

  Anstatt exakt zu rechnen, ziehen wir zufällig aus der Posteriorverteilung und rechnen mit den Samples weiter

---


# Zusammenfassung

Die Bayessche Statistik 

- benutzt Wahrscheinlichkeiten um Unsicherheiten zu beschreiben
- erfordert die Spezifikation von Prior-Verteilungen aller Modellparameter
- hat subjektiven Charakter (aber auch die Wahl der Likelihood ist subjektiv)
- ist oft aufwendig zu berechnen

---