<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Einführung in die Bayessche Statistik</title>
    <meta charset="utf-8" />
    <meta name="author" content="Andreas Brandmaier" />
    <meta name="date" content="2021-02-11" />
    <script src="libs/header-attrs-2.6/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
    <link rel="stylesheet" href="sydney.css" type="text/css" />
    <link rel="stylesheet" href="sydney-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Einführung in die Bayessche Statistik
## <br/>Probelehrveranstaltung
### Andreas Brandmaier
### 2021-02-11

---




# Ziel der Inferenzstatistik

.hide[fill]
.hide[fill]

.larger[

.read_more[Um aus Daten einer begrenzten Anzahl Personen auf eine große Anzahl von Menschen schließen kann, befassen wir uns mit der Inferenzstatistik.] 

.read_more[Allgemeingültigkeit]

.read_more[Quantifizierung der Unsicherheit]

]

&lt;!--.read_more[Typische Fragen in der Psychologie sind:]

 - Wirkt eine neue Therapieform B besser als eine Therapieform A?
- Gibt es einen Zusammenhang zwischen Computerspielen und Gewalt bei Jugendlichen?
- Werden attraktivere Menschen als erfolgreicher eingeschätzt? --&gt;

---


# Ein Beispiel - Mittelwerte schätzen

.emph[Fragestellung: ] Haben Studierende in Potsdam im Mittel einen höheren IQ als 100?

--

.pull-left[

Die Stichprobe ($n=10$) sei:

![](brandmaier-intro_files/figure-html/iq-1.png)&lt;!-- --&gt;
]
.pull-right[

Unsere Modellannahme sei:

IQ-Test Ergebnisse sind normalverteilt mit wahrem Mittelwert `\(\mu\)` und wahrer Varianz `\(\sigma^2\)`.

.read_more[Dabei] sei `\(\mu\)` der unbekannte wahre Mittelwert der Potsdamer Studierenden

]

---

# Frequentistischer Ansatz:

.pull-left[
## Schätzen

Unter allen möglichen Normalverteilungen, wähle die, die am plausibelsten die Daten erzeugt hat:

![](brandmaier-intro_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

Der Stichprobenmittelwert ist hier `\(m=\)` 106.
]

--

.pull-right[
## Testen

Wie plausibel sind die Beobachtungen (oder extremer) unter einem Nullmodell?

![](brandmaier-intro_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

Der p-Wert ist `\(p=\)` 0.25.
]

---

# Frequentistischer Ansatz

.pull-left[
## Schätzen

.largermath[
`$$\arg \max_\theta P\left( D | \theta\right)$$`
]



]

.pull-right[
## Testen

.largermath[

$$P\left(D | \theta_0 \right) $$
]
]

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.med[
.read_more[Wir halten fest, dass beide Ansätze auf .emph[bedingten Wahrscheinlichkeiten] basieren]. Und zwar auf der .emph[Datenwahrscheinlichkeit].
]
---

# Missverständnisse in der frequentistischen Inferenz

.med[Typische Irrtümer:]

--

- Der p-Wert ist die Wahrscheinlichkeit der Null-Hypothese (je kleiner, desto unwahrscheinlicher). Wir glauben mit großer Wahrscheinlichkeit, dass die Nullhypothese falsch ist, wenn `\(p &lt; 0.05\)`.

--

- Wir nehmen an, dass die Nullhypothese (wahrscheinlich) wahr ist (wenn `\(p&gt;0.05\)`)

--

- Das Konfidenzintervall enthält mit 95% Wahrscheinlichkeit den wahren Wert.


--

Offenbar wollen wir oft Aussagen über die .emph[Parameter- oder Hypothesenwahrscheinlichkeit] `\(P\left(\theta | D \right)\)` machen, nutzen zur Inferenz aber die .emph[Datenwahrscheinlichkeit] `\(P\left(D | \theta \right)\)`.

---

class: segue-large-red

.bigfont[
Idee: Können wir `\(P\left(\theta | D \right)\)` aus `\(P\left(D | \theta \right)\)` berechnen?
]

---


# Der Satz von Bayes

Bayesianische Ansätze folgen der folgenden charakteristischen Struktur, die sich aus der bedingten Wahrscheinlichkeit ableiten lassen:

.largemath[
$$P \left( A | B \right) = \frac{ P\left(B | A \right) \times  P\left( A \right)   }{P\left(B \right)  } $$
]

---

#  &amp;#129415; Vampirismus und der Satz von Bayes




Bekannt sei ein Test, der mit einer Erfolgschance von 95% Vampirismus detektiert. Wie hoch ist die Chance, bei positivem Ergebnis, ein Vampir zu sein?

--

.med[
$$P\left( Vampir | + \right) = \frac{ P\left( + | Vampir \right) \times  P\left(Vampir \right)   }{  P\left( + \right)  } $$
]

--

- `\(P \left( + | Vampir \right) =\)` 0.95
- `\(P \left( Vampir \right) =\)` 0.001
- `\(P \left( + \right) =\)`  0.01094

Erlaubt uns den Schluss:

- `\(P \left( Vampir | + \right) =\)` 0.09

.citation[R. McElreath, Statistical Rethinking]

---

# Bayesianischer Ansatz

.read_more[Idee:] Ausgehend von der bekannten Likelihood `\(P\left( Daten | \theta\right)\)`, nutzen wir den Satz von Bayes, um `\(P\left( \theta | Daten \right)\)` zu berechnen

.largermath[
$$ P\left( \theta | Daten \right) = \frac{ P\left(Daten | \theta\right) \cdot P\left( \theta \right) }{ P\left( Daten \right) } $$
]


.hide[Der Nenner `\(P(Daten)\)` ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten]


---

# Bayesianischer Ansatz

.hide[Idee: Ausgehend von der bekannten Likelihood `\(P\left( Daten | \theta \right)\)`, nutzen wir den Satz von Bayes, um `\(P\left( \theta | Daten \right)\)` zu berechnen
]

.largermath[
$$ \underbrace{P\left( \theta | Daten \right)}_{Posterior} = \frac{ \overbrace{P\left(Daten | \theta\right)}^{Likelihood} \cdot \overbrace{P\left( \theta \right)}^{Prior} }{ P\left( Daten \right)  } $$
]


.read_more[Der] Nenner `\(P(Daten)\)` ist im Wesentlichen eine Normierungskonstante, aber wird uns später noch ein paar graue Haare kosten


---

class:segue-large-red

.bigfont[
Aber Moment... was ist denn die _Wahrscheinlichkeit eines Parameters, eines Modells_ oder _einer Hypothese_ überhaupt?
]

---


# Frequentistische Postulate

(nochmal zurück zum Start)

- Wahrscheinlichkeiten beziehen sich auf .emph[relative Häufigkeit] von Ereignisse bei einer großen Anzahl gleicher, wiederholter Durchführungen eines Zufallsexperiments. Wahrscheinlichkeiten sind objektive Eigenschaften der echten Welt.

--

- Die wahren .emph[Parameter sind unbekannte Konstanten]. Weil sie nicht veränderlich sind, kann man keine probabilistischen Aussagen über sie treffen.


---


# Wahrscheinlichkeitsbegriff

.pull-left[

## Frequentistische Perspektive

Wahrscheinlichkeit ist die .emph[relative Häufigkeit] (Frequenz) eines Ereignis bei
sehr häufiger (unendlich oft) Wiederholung

]

--

.pull-right[

## Bayesianische Perspektive

Wahrscheinlichkeit ist der Ausdruck eines .emph[Grad der Überzeugung] (_"degree of belief"_)

]

.pull-down[

Obwohl wir dieselbe Axiomatik der Wahrscheinlichkeitsrechnung nutzen, ist dies ein entscheidender philosophischer Unterschied. 

]

---

# Prior, Likelihood, und Posterior

.pull-left[
Beispiel: Statistisches Modell mit einem Parameter (z.B., Mittlerer IQ)

- .blue[Prior]: Glaubwürdigkeit aller möglichen Mittelwerte
- .red[Likelihood]: Plausibilität gegeben den Daten
- .green[Posterior]: Glaubwürdigkeit nach Beobachtung der Daten

.larger[
.green[Posterior] `\(\propto\)` .red[Likelihood] `\(\times\)` .blue[Prior]
]

]

.pull-right[

![](brandmaier-intro_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

---

# Posterior

Das Ergebnis einer Schätzung ist der Posterior:

.pull-left[

- Enthält nicht nur einen einzelnen Punktschätzer (z.B. Effektstärke)

- Für jeden möglichen Parameterwert erhalten wir eine Wahrscheinlichkeit

- Spezifiziert vollständig unsere Unsicherheit

- Erlaubt (endlich!) Aussagen wie, das 95%-Intervall (.emph[credibility interval]) enthält zu 95% den wahren Parameter
]

.pull-right[

![](brandmaier-intro_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

]

---


class:segue-large-red

.bigfont[
Woher kommt der _Prior_ überhaupt?
]

---

# Beispiel: Beschränkung

![](brandmaier-intro_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

---

# Beispiel: Informierter Prior

![](brandmaier-intro_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---

# Woher kommt der Prior?

Es gibt verschiedene Wege, Priors zu wählen:

- Flache und uninformierte Priors
- Sinnvolle Beschränkungen des Parameterraums (z.B. Nicht-Negativität)
- Vorwissen
- Expertenmeinungen (elicited priors)


---

# Wann spielt der Prior (k)eine Rolle?

.pull-left[
Die Auswirkung der A-Priori-Verteilung ist schwächer,
- je breiter die Verteilung ist (flacher Prior = wenig Vorinformation)
- je mehr Daten wir beobachten
]

.pull-right[
![](brandmaier-intro_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
]
---

# Bayessche Integrale

Für viele Bayessche Anwendung benötigen wir Integrale, z.B., für

-   Berechnung der Evidenz in der Posterior-Verteilung:

$$P\left(\theta | D \right) = \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ P\left D \right) } =  \frac{ P\left( D | \theta \right) \cdot P\left(\theta \right) }{ \int{ P\left( D | \theta  \right) P\left(\theta \right)} d\theta } $$
- Punkt- und Intervallschätzer, wie z.B. Mean oder Credibility Region

$$\hat{\mu} = \int \theta \cdot P\left(\theta | D \right)  d\theta $$
  

- Randverteilung einzelner Parameter
- Modellvergleich mit dem .emph[Bayes Faktor]

---

# Bayesianische Integrale lösen

Es existieren verschiedene Ansätze:

.read_more[] Analytische Lösungen mit .emph[konjugierten Priors]

  Bestimmte statistische Modelle haben Priors, die zu Posteriors führen, die aus derselben Verteilungsfamilie stammen
  
- Approximationen wie bspw. .emph[Variational Bayes]

  Finde einfache Verteilungen, die den wahren Posterior annähern
  
- .emph[Monte Carlo Markov Chains] (MCMC)

  Anstatt exakt zu rechnen, ziehen wir zufällig aus der Posteriorverteilung und rechnen mit den Samples weiter

---


# Zusammenfassung

Die Bayessche Statistik 

- erlaubt Aussagen über die Parameter- und Hypothesenwahrscheinlichkeit anstatt über die Datenwahrscheinlichkeiten
- benutzt Wahrscheinlichkeiten um Unsicherheiten zu beschreiben
- erfordert die Spezifikation von Prior-Verteilungen aller Modellparameter
- hat eher subjektiven Charakter (aber auch die Wahl der Likelihood ist subjektiv), aber Priors können auch uninformativ gewählt werden
- ist oft aufwendig zu berechnen, aber verschiedene praktische Lösungen existieren

---


# Testen mit dem Bayes Factor

- Bayesianer formulieren eine explizite Alternative, gegen die getestet werden kann, bspw: 
    - `\(H_1\)`: Der mittlere IQ ist 0
    - Die Prior-Verteilung betrifft dann nur noch die übrigen Parameter, hier, die Varianz.

- Testen wird als Modellvergleich durchgeführt:

$$BF_{10}=\frac{P\left(D | H_1\right)}{P\left(D | H_0\right)} $$
- Dies korrespondiert zu der Logik des Likelihood-Ratio Tests unter Berücksichtigung der kompletten Unsicherheit im Posterior
---

class: segue-large-gold

.bigfont[
Und was ist daran so kompliziert?
]
---
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
